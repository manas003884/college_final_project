# -*- coding: utf-8 -*-
"""RC4 + Steganography + CNN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LhlM_wqYySe5I7LbgKL31nq8yipDa7zf
"""

import codecs
import numpy as np
import pandas as pd
from rc4 import rc4
from steganography import Steganography
from cnn import Net
import cv2

import torch
import torch.nn as nn
import torchvision.transforms as transforms
import torchvision.datasets as datasets
from torch.autograd import Variable
torch.cuda.is_available()

from google.colab import drive
drive.mount('/content/gdrive')

cipher = rc4("Rachit", 'not-so-random-key')
ciphertext = cipher.encrypt()

input = []
for i in range(301, 501):
  image = cv2.imread('/content/gdrive/My Drive/Images/' + str(i) + '.jpg')
  filename = '/content/gdrive/My Drive/EncryptedImages/' + 'Encrypted' + str(i) + '.png'
  EncryptedImg = Steganography(image, ciphertext, filename)
  EncryptedImage = EncryptedImg.encode_data()
  EncryptedImage.resize(3, 512, 512)
  image.resize(3, 512, 512)
  input.append(EncryptedImage)
  input.append(image)

net = Net()
print(net)

input = np.array(input)
input = torch.from_numpy(input)
input = input.type(torch.FloatTensor)

import numpy as np
import pandas as pd
from google.colab import files

df=pd.read_csv('target.csv')

key_pts = df.iloc[0:302, 0:1].values

key_pts = torch.from_numpy(key_pts)
key_pts = key_pts.type(torch.FloatTensor)

import torch.optim as optim
criterion = nn.MSELoss()
optimizer = optim.Adam(params = net.parameters(), lr = 0.001)

"""## **Training**"""

def train_net(n_epochs, input, key_pts):
    net.train()
    for epoch in range(n_epochs):
        running_loss = 0.0
        for i in range(300):#len(input)
          output_pts = net(input[i].reshape(1, 3, 512, 512))
          loss = criterion(output_pts, key_pts[i])
          optimizer.zero_grad()
          loss.backward()
          optimizer.step()
          running_loss += loss.item()
          print('Epoch: {}, Batch: {}, Avg. Loss: {}'.format(epoch + 1, i+1, running_loss/10))
          running_loss = 0.0
    print('Finished Training')

train_net(3, input, key_pts)

"""# **Save the model parameters**"""

model_dir = '/content/gdrive/My Drive/saved_models/'
model_name = 'model_4.pt'
torch.save(net.state_dict(), model_dir+model_name)

"""#Import model Parameters"""

import torch
from cnn import Net
net = Net()
net.load_state_dict(torch.load('/content/gdrive/My Drive/saved_models/model_2.pt'))
net.eval()

"""## **Testing**"""

import cv2
import numpy
finalList = []
for i in range(491, 501, 1):
  testingImage = cv2.imread('/content/gdrive/My Drive/EncryptedImages/Encrypted' + str(i) + '.png')
  testingImage.resize(3, 512, 512)
  testingImage = torch.from_numpy(testingImage)
  testingImage = testingImage.type(torch.FloatTensor)
  output = net(testingImage.reshape(1, 3, 512, 512))
  output = output.cpu().data.numpy()
  finalList.append(output[0])

finalList = numpy.asarray(finalList)
finalList = numpy.round(finalList, decimals=1)
np.savetxt('/content/gdrive/My Drive/finalList/finalList40.csv', finalList, delimiter=",")

df = pd.read_csv('/content/gdrive/My Drive/finalList/normalImages.csv')
finalListNormal = df.iloc[0:192, 0:1].values

count1 = 0
for i in range(190):
  if finalListNormal[i] <= 0.5:
    count1 += 1

df = pd.read_csv('/content/gdrive/My Drive/finalList/encryptedImages.csv')
finalListEncrypted = df.iloc[0:192, 0:1].values

count2 = 0
for i in range(190):
  if finalListEncrypted[i] > 0.5:
    count2 += 1

count1

count2